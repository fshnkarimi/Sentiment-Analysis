{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project_phase1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_JeUZD23c57"
      },
      "source": [
        "'''\n",
        "    Afshin Karimi\n",
        "    99210431\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWiQrtuGqYAZ"
      },
      "source": [
        "## Initialaize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--m1GNjdqbKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a139415c-765d-4176-e88e-3f3264f66b56"
      },
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from prettytable import PrettyTable"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AL1xYgfqa89"
      },
      "source": [
        "def analysis(labels, predictions):\n",
        "    print(f\"Report: Classification\\n{classification_report(labels, predictions, target_names=['positive','negative'])}\")\n",
        "    print(f\"Matrix: Confusion\\n{confusion_matrix(labels, predictions)}\")\n",
        "    print(f\"Accuracy: \\n{accuracy_score(labels, predictions)}\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND7VuMdtqbHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c19bd6-bb3f-4960-f9e0-fd4bd55b3300"
      },
      "source": [
        "# connect to my drive for loading dataset\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m162JmPlqbE-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d0aa4e4c-8569-4cf0-a316-0b62faa92dca"
      },
      "source": [
        "# load dataset\n",
        "df = pd.read_csv('/content/gdrive/My Drive/Datasets/dataset.csv')\n",
        "df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oh my god, it just doesn't get any worse than ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you're a layman interested in quantum theor...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's amazing that this no talent actor Chapa g...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This must be one of the most overrated Spanish...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Some critics have compared Chop Shop with the ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment sentiment\n",
              "0  Oh my god, it just doesn't get any worse than ...  negative\n",
              "1  If you're a layman interested in quantum theor...  negative\n",
              "2  It's amazing that this no talent actor Chapa g...  negative\n",
              "3  This must be one of the most overrated Spanish...  negative\n",
              "4  Some critics have compared Chop Shop with the ...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3D6RHg8A-p9E",
        "outputId": "35242096-a4e5-43d3-fe62-4b6943639039"
      },
      "source": [
        "# convert sentiment results to number {0,1}\n",
        "df['sentiment'].replace('negative',0,inplace=True)\n",
        "df['sentiment'].replace('positive',1,inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oh my god, it just doesn't get any worse than ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you're a layman interested in quantum theor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's amazing that this no talent actor Chapa g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This must be one of the most overrated Spanish...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Some critics have compared Chop Shop with the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment  sentiment\n",
              "0  Oh my god, it just doesn't get any worse than ...          0\n",
              "1  If you're a layman interested in quantum theor...          0\n",
              "2  It's amazing that this no talent actor Chapa g...          0\n",
              "3  This must be one of the most overrated Spanish...          0\n",
              "4  Some critics have compared Chop Shop with the ...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmW2Iziyg1id"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hLVyL0IqbCP"
      },
      "source": [
        "def preprocess(df, mode = 'low'):\n",
        "    df_copy = df.copy()\n",
        "    # convert all comments to lowercase\n",
        "    df_copy[\"comment\"] = df_copy[\"comment\"].str.lower()\n",
        "    # remove numbers from comments\n",
        "    df_copy['comment'] = df_copy['comment'].str.replace('\\d+', '')\n",
        "    # remove special characters\n",
        "    df_copy.replace(r'[^A-Za-z0-9 ]+', '', regex=True,inplace=True)\n",
        "    # word tokenize\n",
        "    df_copy['comment']=df_copy['comment'].apply(word_tokenize)\n",
        "    if mode == 'high':\n",
        "        # stop words removal\n",
        "        stopword = stopwords.words('english')\n",
        "        df_copy['comment'] = df_copy['comment'].apply(lambda x: [item for item in x if item not in stopword])\n",
        "        # lemma\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        df_copy['comment'] = df_copy['comment'].apply(lambda x: [lemmatizer.lemmatize(w) for w in x])\n",
        "        # stemming\n",
        "        snowball_stemmer = SnowballStemmer('english')\n",
        "        df_copy['comment'] = df_copy['comment'].apply(lambda x: [snowball_stemmer.stem(w) for w in x])\n",
        "        # Removal of Frequent words\n",
        "        cnt = Counter()\n",
        "        for text in df_copy[\"comment\"].values:\n",
        "            for word in text:\n",
        "                cnt[word] += 1\n",
        "        FREQWORDS = set([w for (w, wc) in cnt.most_common(6)])\n",
        "        df_copy[\"comment\"] = df_copy[\"comment\"].apply(lambda text: list([word for word in text if word not in FREQWORDS]))\n",
        "        # Removal of Rare words\n",
        "        n_rare_words = 10\n",
        "        RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
        "        df_copy[\"comment\"] = df_copy[\"comment\"].apply(lambda text: list([word for word in text if word not in RAREWORDS]))\n",
        "    return df_copy"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBsnphZZir5z"
      },
      "source": [
        "df_low = preprocess(df, mode = 'low')\n",
        "df_high = preprocess(df, mode = 'high')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGxd-hEdg6Vh"
      },
      "source": [
        "### Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq_foje_qa_o"
      },
      "source": [
        "def vectorize(df, vectorization_type = 'bow', is_preprocessed = True , bow_features_num = 1000, w2v_size = 200):\n",
        "    bow_model = None\n",
        "    df_comments = df['comment']\n",
        "    if vectorization_type == 'bow':\n",
        "        bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=bow_features_num)\n",
        "        if is_preprocessed:\n",
        "            df_comments = [' '.join([str(elem) for elem in sublist]) for sublist in df['comment']]\n",
        "        bow_model = bow_vectorizer.fit_transform(df_comments)\n",
        "        return bow_model\n",
        "    elif vectorization_type == 'w2v':\n",
        "        w2v_vectorizer = gensim.models.Word2Vec(df['comment'],\n",
        "                     min_count=20,\n",
        "                     size=w2v_size,\n",
        "                     workers=8)\n",
        "        wordvec_arrays = np.zeros((len(df['comment']), w2v_size)) \n",
        "        for i in range(len(df['comment'])):\n",
        "            wordvec_arrays[i,:] = word_vector(df['comment'][i], w2v_size,w2v_vectorizer)\n",
        "        w2v_model = pd.DataFrame(wordvec_arrays)\n",
        "        return w2v_model\n",
        "    bow_vectorizer.fit_transform(df['comment'])\n",
        "    return\n",
        "\n",
        "# create a vector for each comment by taking the average of the vectors of the words present in the comment.\n",
        "def word_vector(tokens, size, w2v_vectorizer):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += w2v_vectorizer[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:  # handling the case where the token is not in vocabulary\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO3ObIj3i6cV"
      },
      "source": [
        "model = vectorize(df, is_preprocessed = False)\n",
        "model_low = vectorize(df_low, vectorization_type='bow')\n",
        "model_high = vectorize(df_high, vectorization_type='bow')\n",
        "model_w2v = vectorize(df_high, vectorization_type='w2v')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38LEh9Mqa6g"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGOhtCQ538Yc"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP5bdsCQ57ZS"
      },
      "source": [
        "lr_dict = {}\n",
        "\n",
        "def log_reg(model, labels, mode = 0):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(model, labels, train_size=0.8)\n",
        "    for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "        results = []\n",
        "        lr = LogisticRegression(C=c)\n",
        "        lr.fit(X_train, y_train)\n",
        "        acc_score = accuracy_score(y_test, lr.predict(X_test))\n",
        "        results.append(c)\n",
        "        print('Accuracy for C=%s: %s'\n",
        "            % (c, acc_score))\n",
        "    nl = '\\n'\n",
        "    best_c = max(results)\n",
        "    print(f'{nl}So the best C is : {best_c}')\n",
        "    lr_model = LogisticRegression(C=best_c)\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    predictions = lr_model.predict(X_test)\n",
        "    score = accuracy_score(y_test, predictions)\n",
        "    if mode == 0:\n",
        "        lr_dict['LR without preprocess(BoW)'] = score\n",
        "    elif mode == 1:\n",
        "        lr_dict['LR with low preprocess(BoW)'] = score\n",
        "    elif mode == 2:\n",
        "        lr_dict['LR with high preprocess(BoW)'] = score\n",
        "    elif mode == 3:\n",
        "        lr_dict['LR with high preprocess(w2v)'] = score\n",
        "    analysis(y_test,predictions)\n",
        "    return lr_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxDD4_vj4GIt",
        "outputId": "50877aff-cba0-429f-d2b0-32ec68932946"
      },
      "source": [
        "# Bag-of-Words without preprocess\n",
        "lr_model1 = log_reg(model,df['sentiment'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.8674444444444445\n",
            "Accuracy for C=0.05: 0.8688888888888889\n",
            "Accuracy for C=0.25: 0.8668888888888889\n",
            "Accuracy for C=0.5: 0.8666666666666667\n",
            "Accuracy for C=1: 0.8661111111111112\n",
            "\n",
            "So the best C is : 1\n",
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.87      0.86      0.87      4495\n",
            "    negative       0.86      0.87      0.87      4505\n",
            "\n",
            "    accuracy                           0.87      9000\n",
            "   macro avg       0.87      0.87      0.87      9000\n",
            "weighted avg       0.87      0.87      0.87      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3864  631]\n",
            " [ 574 3931]]\n",
            "Accuracy: \n",
            "0.8661111111111112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO1ZkSVC4GMx",
        "outputId": "f6ff0bae-5053-4456-e96b-7ea19b7000cc"
      },
      "source": [
        "# Bag-of-Words with low preprocess\n",
        "lr_model2 = log_reg(model_low, df['sentiment'], mode=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.8666666666666667\n",
            "Accuracy for C=0.05: 0.8654444444444445\n",
            "Accuracy for C=0.25: 0.8643333333333333\n",
            "Accuracy for C=0.5: 0.8628888888888889\n",
            "Accuracy for C=1: 0.8632222222222222\n",
            "\n",
            "So the best C is : 1\n",
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.87      0.86      0.86      4510\n",
            "    negative       0.86      0.87      0.86      4490\n",
            "\n",
            "    accuracy                           0.86      9000\n",
            "   macro avg       0.86      0.86      0.86      9000\n",
            "weighted avg       0.86      0.86      0.86      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3875  635]\n",
            " [ 596 3894]]\n",
            "Accuracy: \n",
            "0.8632222222222222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwMqOGhE4GGc",
        "outputId": "beff46b4-e616-4445-cbdb-2845bcfa5ebd"
      },
      "source": [
        "# Bag-of-Words with high preprocess\n",
        "lr_model3 = log_reg(model_high, df['sentiment'], mode=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.8563333333333333\n",
            "Accuracy for C=0.05: 0.8561111111111112\n",
            "Accuracy for C=0.25: 0.8544444444444445\n",
            "Accuracy for C=0.5: 0.8541111111111112\n",
            "Accuracy for C=1: 0.8537777777777777\n",
            "\n",
            "So the best C is : 1\n",
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.86      0.84      0.85      4507\n",
            "    negative       0.84      0.87      0.86      4493\n",
            "\n",
            "    accuracy                           0.85      9000\n",
            "   macro avg       0.85      0.85      0.85      9000\n",
            "weighted avg       0.85      0.85      0.85      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3788  719]\n",
            " [ 597 3896]]\n",
            "Accuracy: \n",
            "0.8537777777777777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOBLf7_d4F7E",
        "outputId": "d08b25b5-66af-4c4a-83aa-85687c143c8a"
      },
      "source": [
        "# Word2Vec with high preprocess\n",
        "lr_model4 = log_reg(model_w2v, df['sentiment'], mode=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for C=0.01: 0.8631111111111112\n",
            "Accuracy for C=0.05: 0.871\n",
            "Accuracy for C=0.25: 0.874\n",
            "Accuracy for C=0.5: 0.8747777777777778\n",
            "Accuracy for C=1: 0.8768888888888889\n",
            "\n",
            "So the best C is : 1\n",
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.88      0.87      0.88      4469\n",
            "    negative       0.88      0.88      0.88      4531\n",
            "\n",
            "    accuracy                           0.88      9000\n",
            "   macro avg       0.88      0.88      0.88      9000\n",
            "weighted avg       0.88      0.88      0.88      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3899  570]\n",
            " [ 538 3993]]\n",
            "Accuracy: \n",
            "0.8768888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf260oSe4F3h",
        "outputId": "f7839d78-33cd-4d7f-c477-c69f91274122"
      },
      "source": [
        "lr_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LR with high preprocess(BoW)': 0.8537777777777777,\n",
              " 'LR with high preprocess(w2v)': 0.8768888888888889,\n",
              " 'LR with low preprocess(BoW)': 0.8632222222222222,\n",
              " 'LR without preprocess(BoW)': 0.8661111111111112}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeZBPBhYHvQK"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OenMraqIIwL"
      },
      "source": [
        "knn_dict = {}\n",
        "\n",
        "def best_k(X_train, y_train):\n",
        "    param_grid = {'n_neighbors':np.arange(9,12)}\n",
        "    knn = KNeighborsClassifier()\n",
        "    knn_cv= GridSearchCV(knn,param_grid,cv=5)\n",
        "    knn_cv.fit(X_train, y_train)\n",
        "    nl = '\\n'\n",
        "    bestk = knn_cv.best_params_['n_neighbors']\n",
        "    print(f'Best score is {knn_cv.best_score_} for k = {bestk} {nl}')\n",
        "    return bestk\n",
        "\n",
        "def KNN(model, labels, mode = 0):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(model, labels, train_size=0.8)\n",
        "    best_k_num = best_k(X_train, y_train)\n",
        "    #Setup a knn classifier with k neighbors\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=best_k_num)\n",
        "    #Fit the model\n",
        "    knn_model.fit(X_train, y_train)\n",
        "    predictions = knn_model.predict(X_test)\n",
        "    score = accuracy_score(y_test, predictions)\n",
        "    if mode == 0:\n",
        "        knn_dict['kNN without preprocess(BoW)'] = score\n",
        "    elif mode == 1:\n",
        "        knn_dict['kNN with low preprocess(BoW)'] = score\n",
        "    elif mode == 2:\n",
        "        knn_dict['kNN with high preprocess(BoW)'] = score\n",
        "    elif mode == 3:\n",
        "        knn_dict['kNN with high preprocess(w2v)'] = score\n",
        "    analysis(y_test,predictions)\n",
        "    return knn_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb7wKBgJJoG1",
        "outputId": "d489b1ec-ac33-4333-c95a-f0e7edda5a99"
      },
      "source": [
        "# Bag-of-Words without preprocess (KNN)\n",
        "knn_model1 = KNN(model,df['sentiment'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score is 0.6520277777777779 for k = 10 \n",
            "\n",
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.67      0.65      0.66      4587\n",
            "    negative       0.64      0.66      0.65      4413\n",
            "\n",
            "    accuracy                           0.65      9000\n",
            "   macro avg       0.65      0.65      0.65      9000\n",
            "weighted avg       0.65      0.65      0.65      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[2975 1612]\n",
            " [1496 2917]]\n",
            "Accuracy: \n",
            "0.6546666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVWJDU50H1kc",
        "outputId": "ff5954ae-8912-409e-c7e2-bde8ea678c54"
      },
      "source": [
        "# Bag-of-Words with low preprocess (KNN)\n",
        "knn_model2 = KNN(model_low,df['sentiment'],mode=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score is 0.6554166666666666 for k = 10 \n",
            "\n",
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.65      0.66      0.65      4435\n",
            "    negative       0.66      0.66      0.66      4565\n",
            "\n",
            "    accuracy                           0.66      9000\n",
            "   macro avg       0.66      0.66      0.66      9000\n",
            "weighted avg       0.66      0.66      0.66      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[2916 1519]\n",
            " [1570 2995]]\n",
            "Accuracy: \n",
            "0.6567777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpXURzWyH1iA",
        "outputId": "8c8c8f91-1fc0-4bde-9c0b-b4cdb7bba4dd"
      },
      "source": [
        "# Bag-of-Words with high preprocess (KNN)\n",
        "knn_model3 = KNN(model_high,df['sentiment'],mode=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score is 0.69675 for k = 11 \n",
            "\n",
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.69      0.70      0.70      4473\n",
            "    negative       0.70      0.69      0.70      4527\n",
            "\n",
            "    accuracy                           0.70      9000\n",
            "   macro avg       0.70      0.70      0.70      9000\n",
            "weighted avg       0.70      0.70      0.70      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3131 1342]\n",
            " [1395 3132]]\n",
            "Accuracy: \n",
            "0.6958888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ireZ0P4mH1ff",
        "outputId": "5b39e092-f41d-434e-b89d-8319b11827db"
      },
      "source": [
        "# Word2Vec with high preprocess (KNN)\n",
        "knn_model4 = KNN(model_w2v, df['sentiment'], mode=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score is 0.8166944444444445 for k = 11 \n",
            "\n",
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.81      0.84      0.82      4513\n",
            "    negative       0.83      0.80      0.82      4487\n",
            "\n",
            "    accuracy                           0.82      9000\n",
            "   macro avg       0.82      0.82      0.82      9000\n",
            "weighted avg       0.82      0.82      0.82      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3789  724]\n",
            " [ 899 3588]]\n",
            "Accuracy: \n",
            "0.8196666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqgZIjfiH1dB",
        "outputId": "04a543b8-0efe-451e-92e7-814a61a6510b"
      },
      "source": [
        "knn_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kNN with high preprocess(BoW)': 0.6958888888888889,\n",
              " 'kNN with high preprocess(w2v)': 0.8196666666666667,\n",
              " 'kNN with low preprocess(BoW)': 0.6567777777777778,\n",
              " 'kNN without preprocess(BoW)': 0.6546666666666666}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-AD6rMcHyHc"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILKulGVYH1D3"
      },
      "source": [
        "svm_dict = {}\n",
        "\n",
        "def svm(model, labels, mode = 0):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(model, labels, train_size=0.8)\n",
        "    svm_model = SGDClassifier()\n",
        "    svm_model.fit(X_train, y_train)\n",
        "    predictions = svm_model.predict(X_test)\n",
        "    score = accuracy_score(y_test, predictions)\n",
        "    if mode == 0:\n",
        "        svm_dict['SVM without preprocess(BoW)'] = score\n",
        "    elif mode == 1:\n",
        "        svm_dict['SVM with low preprocess(BoW)'] = score\n",
        "    elif mode == 2:\n",
        "        svm_dict['SVM with high preprocess(BoW)'] = score\n",
        "    elif mode == 3:\n",
        "        svm_dict['SVM with high preprocess(w2v)'] = score\n",
        "    analysis(y_test,predictions)\n",
        "    return svm_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqza6mxaH1A0",
        "outputId": "5459411d-b05f-42d2-94a6-267558110807"
      },
      "source": [
        "# Bag-of-Words without preprocess (SVM)\n",
        "svm_model1 = svm(model,df['sentiment'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.92      0.77      0.84      4476\n",
            "    negative       0.80      0.93      0.86      4524\n",
            "\n",
            "    accuracy                           0.85      9000\n",
            "   macro avg       0.86      0.85      0.85      9000\n",
            "weighted avg       0.86      0.85      0.85      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3431 1045]\n",
            " [ 310 4214]]\n",
            "Accuracy: \n",
            "0.8494444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bobPcosaH0-K",
        "outputId": "19561a73-5886-4e79-c3e8-110f25092ff1"
      },
      "source": [
        "# Bag-of-Words with low preprocess (SVM)\n",
        "svm_model2 = svm(model_low, df['sentiment'], mode=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.84      0.88      0.86      4476\n",
            "    negative       0.88      0.83      0.85      4524\n",
            "\n",
            "    accuracy                           0.86      9000\n",
            "   macro avg       0.86      0.86      0.86      9000\n",
            "weighted avg       0.86      0.86      0.86      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3955  521]\n",
            " [ 781 3743]]\n",
            "Accuracy: \n",
            "0.8553333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKn6NZOAH07j",
        "outputId": "d997e926-2b31-4fb9-d473-b3fd99e38150"
      },
      "source": [
        "# Bag-of-Words with high preprocess (SVM)\n",
        "svm_model3 = svm(model_high, df['sentiment'], mode=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.89      0.80      0.84      4476\n",
            "    negative       0.82      0.90      0.86      4524\n",
            "\n",
            "    accuracy                           0.85      9000\n",
            "   macro avg       0.86      0.85      0.85      9000\n",
            "weighted avg       0.86      0.85      0.85      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3583  893]\n",
            " [ 443 4081]]\n",
            "Accuracy: \n",
            "0.8515555555555555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msv12jqGmlBF",
        "outputId": "1bb515fa-f5c3-41a8-e1b7-359e6ca53734"
      },
      "source": [
        "# Word2Vec with high preprocess (SVM)\n",
        "svm_model4 = svm(model_w2v, df['sentiment'], mode=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.90      0.78      0.84      4476\n",
            "    negative       0.81      0.91      0.86      4524\n",
            "\n",
            "    accuracy                           0.85      9000\n",
            "   macro avg       0.86      0.85      0.85      9000\n",
            "weighted avg       0.85      0.85      0.85      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3506  970]\n",
            " [ 388 4136]]\n",
            "Accuracy: \n",
            "0.8491111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4llPD4km4TM",
        "outputId": "605ff719-d691-4c73-8325-2e8336fe6e41"
      },
      "source": [
        "svm_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'SVM with high preprocess(BoW)': 0.8515555555555555,\n",
              " 'SVM with high preprocess(w2v)': 0.8491111111111111,\n",
              " 'SVM with low preprocess(BoW)': 0.8553333333333333,\n",
              " 'SVM without preprocess(BoW)': 0.8494444444444444}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4NxXn23hNDO"
      },
      "source": [
        "## Evaluate and save best results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6amQGWrUhTw4"
      },
      "source": [
        "def print_results(result_dict):\n",
        "    t = PrettyTable(['model', 'accuracy'])\n",
        "    for key, val in result_dict.items():\n",
        "        t.add_row([key, val])\n",
        "    print(t)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htvn0D2bhTp2"
      },
      "source": [
        "def save_model(model, model_name):\n",
        "    model_name = model_name + '.pkl'\n",
        "    with open(model_name,'wb') as f:\n",
        "        pickle.dump(model,f)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7M9FWj3hTfu",
        "outputId": "fa117aa4-91bd-42fa-96b7-0280a0190128"
      },
      "source": [
        "print_results(lr_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+--------------------+\n",
            "|            model             |      accuracy      |\n",
            "+------------------------------+--------------------+\n",
            "|  LR without preprocess(BoW)  | 0.8661111111111112 |\n",
            "| LR with low preprocess(BoW)  | 0.8632222222222222 |\n",
            "| LR with high preprocess(BoW) | 0.8537777777777777 |\n",
            "| LR with high preprocess(w2v) | 0.8768888888888889 |\n",
            "+------------------------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEzVlSw8kgJa"
      },
      "source": [
        "# save LR with high preprocess(w2v) according to above results\n",
        "save_model(lr_model4,'LR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3TvuoprkgGc",
        "outputId": "89fe1031-3df3-46f8-bac5-0162d6fe7caa"
      },
      "source": [
        "print_results(knn_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------+--------------------+\n",
            "|             model             |      accuracy      |\n",
            "+-------------------------------+--------------------+\n",
            "|  kNN without preprocess(BoW)  | 0.6546666666666666 |\n",
            "|  kNN with low preprocess(BoW) | 0.6567777777777778 |\n",
            "| kNN with high preprocess(BoW) | 0.6958888888888889 |\n",
            "| kNN with high preprocess(w2v) | 0.8196666666666667 |\n",
            "+-------------------------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOt9H-NQkgDr"
      },
      "source": [
        "# save kNN with high preprocess(w2v) according to above results\n",
        "save_model(knn_model4,'kNN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OOybRy1lKnZ",
        "outputId": "259d91cb-4367-4aa4-9898-a50c31281684"
      },
      "source": [
        "print_results(svm_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------+--------------------+\n",
            "|             model             |      accuracy      |\n",
            "+-------------------------------+--------------------+\n",
            "|  SVM without preprocess(BoW)  | 0.8494444444444444 |\n",
            "|  SVM with low preprocess(BoW) | 0.8553333333333333 |\n",
            "| SVM with high preprocess(BoW) | 0.8515555555555555 |\n",
            "| SVM with high preprocess(w2v) | 0.8491111111111111 |\n",
            "+-------------------------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiRmKdSqlKaT"
      },
      "source": [
        "# save SVM with low preprocess(BoW) according to above results\n",
        "save_model(svm_model2,'SVM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3UjkpE32xgp"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsKtYIcMQo1j"
      },
      "source": [
        "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=500)\n",
        "df_comments = [' '.join([str(elem) for elem in sublist]) for sublist in df_high['comment']]\n",
        "model_high = bow_vectorizer.fit_transform(df_comments)\n",
        "pickle.dump(bow_vectorizer,open('bow_vectorizer.pkl','wb'))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSzWJNvytMRS"
      },
      "source": [
        "X = model_high\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwmDeK-eiw9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f93431e-8838-4533-8dde-bf9211b125c3"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp_model = MLPClassifier(hidden_layer_sizes=250, activation='relu', max_iter=300, warm_start=True)\n",
        "mlp_model.partial_fit(X_train, y_train,classes=np.unique(y_train))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=250, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSzUHT2ltVqc",
        "outputId": "2fc31006-5c2d-4028-ecd7-bd03128c60ca"
      },
      "source": [
        "predictions = mlp_model.predict(X_test)\n",
        "analysis(y_test,predictions)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Report: Classification\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.85      0.87      0.86      4480\n",
            "    negative       0.87      0.85      0.86      4520\n",
            "\n",
            "    accuracy                           0.86      9000\n",
            "   macro avg       0.86      0.86      0.86      9000\n",
            "weighted avg       0.86      0.86      0.86      9000\n",
            "\n",
            "Matrix: Confusion\n",
            "[[3900  580]\n",
            " [ 693 3827]]\n",
            "Accuracy: \n",
            "0.8585555555555555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHNWffqDtriK"
      },
      "source": [
        "pickle.dump(mlp_model,open('best.pkl','wb'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra03UgfDtybl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}